{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33bcd903-3844-4bd1-bee9-1aa0f0922d4b",
   "metadata": {},
   "source": [
    "# Predicting question topic from weather forecasts\n",
    "\n",
    "This is the cleaned up code used to train a question topic prediction model. The first cell loads the data; the filepath and file names should be updated as needed.\n",
    "\n",
    "The data in the original analysis and training was loaded without compression. If the datasets are too large, you may need to do additional steps here to load it all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a9c386-5887-43ff-b49d-35dc281c8e06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#------------------#\n",
    "# Loading the data #\n",
    "#------------------#\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Replace this string with the filepath to the datasets on your machine!\n",
    "filepath = r'C:\\\\Users\\\\quinn\\\\Downloads\\\\'\n",
    "\n",
    "# If for some reason the datasets have been renamed, update the following strings (We Farm dataset, Uganda weather, Tanzania weather, and Kenya weather,\n",
    "# respectively)\n",
    "topics = 'DataKit_Fall_2025.csv'\n",
    "uganda = 'UGA_weather_data.csv'\n",
    "tanzania = 'TZA_weather_data.csv'\n",
    "kenya = 'KEN_weather_data.csv'\n",
    "\n",
    "# Load the datasets\n",
    "df_topics = pd.read_csv(filepath+topics)\n",
    "df_ug_w = pd.read_csv(filepath+uganda)\n",
    "df_tz_w = pd.read_csv(filepath+tanzania)\n",
    "df_ke_w = pd.read_csv(filepath+kenya)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef2dedf-3379-43f7-ae0e-c13c1d752dab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a4d32b-4678-414f-85b2-de41709f68b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quinn\\AppData\\Local\\Temp\\ipykernel_33800\\3365017820.py:33: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df_model = df_model[features+labels].interpolate(method='linear')\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------#\n",
    "# Set up the dataframe for the model #\n",
    "#------------------------------------#\n",
    "\n",
    "# Some questions have multiple rows; remove the duplicates\n",
    "df_topics = df_topics.drop_duplicates(subset=['question_content'])\n",
    "\n",
    "# Convert the timestamps to YYYY-MM format\n",
    "df_topics['question_sent'] = pd.to_datetime(df_topics['question_sent'],format='mixed').dt.strftime(\"%Y-%m\")\n",
    "\n",
    "\n",
    "# We only need to keep the question asker's topic, country code, and timestamp columns from the We Farm dataset\n",
    "# Drop the unneeded columns and remove any remaining rows with NA values\n",
    "keep_columns = ['question_topic','question_user_country_code','question_sent']\n",
    "df_topics = df_topics[keep_columns].dropna()\n",
    "\n",
    "# Now, split up country-specific dataframes\n",
    "df_ug_topics = df_topics[df_topics.question_user_country_code == 'ug']\n",
    "df_tz_topics = df_topics[df_topics.question_user_country_code == 'tz']\n",
    "df_ke_topics = df_topics[df_topics.question_user_country_code == 'ke']\n",
    "\n",
    "# Merge the question topics with the weather data, matching on the year and month of the data\n",
    "df_ug_merged = pd.merge(df_ug_topics,df_ug_w,how='inner',left_on='question_sent',right_on='index')\n",
    "df_tz_merged = pd.merge(df_tz_topics,df_tz_w,how='inner',left_on='question_sent',right_on='index')\n",
    "df_ke_merged = pd.merge(df_ke_topics,df_ke_w,how='inner',left_on='question_sent',right_on='index')\n",
    "\n",
    "# Put all of our rows together into one dataframe again\n",
    "df_model = pd.concat([df_ug_merged,df_tz_merged,df_ke_merged])\n",
    "\n",
    "# Retain only the columns used in the model and interpolate missing weather data\n",
    "features = ['avg_max_temp','precipitation','relative_humidity','avg_min_temp']\n",
    "labels = ['question_topic']\n",
    "df_model = df_model[features+labels].interpolate(method='linear')\n",
    "\n",
    "# Lastly, retain only the question topics that will be used in the model\n",
    "topic_list = ['bean', 'cattle', 'chicken', 'coffee', 'goat', 'maize', 'pig', 'potato', 'poultry', 'rabbit', 'tomato']\n",
    "df_model = df_model[df_model['question_topic'].isin(topic_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a9015a-5983-4798-8767-aeacfb0fc67e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2ec375e-183b-4e1b-8cac-6e5fc999a2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('xform',\n",
       "                                        ColumnTransformer(remainder=StandardScaler(),\n",
       "                                                          transformers=[])),\n",
       "                                       ('rf',\n",
       "                                        RandomForestClassifier(class_weight='balanced',\n",
       "                                                               random_state=42))]),\n",
       "             param_grid={'rf__max_depth': [9], 'rf__max_features': [None],\n",
       "                         'rf__min_samples_leaf': [1],\n",
       "                         'rf__min_samples_split': [2],\n",
       "                         'rf__n_estimators': [100]})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------#\n",
    "# Training the model #\n",
    "#--------------------#\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "X = df_model[features]\n",
    "y = df_model['question_topic']\n",
    "\n",
    "\n",
    "# Scale the data\n",
    "col_x = ColumnTransformer([\n",
    "    ], \n",
    "    remainder=StandardScaler())\n",
    "\n",
    "col_x.fit(X);\n",
    "X_transformed = col_x.transform(X[features])\n",
    "\n",
    "# Seed specified for the sake of reproducability\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[features], y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 'balanced' class weighting due to the imbalance of classes\n",
    "rf_pipe = Pipeline([('xform', col_x),\n",
    "                    ('rf', RandomForestClassifier(random_state=42, class_weight='balanced'))])\n",
    "\n",
    "# Parameters for the model (determined based on previous grid searches):\n",
    "parameters = {\n",
    "    'rf__n_estimators': [100],\n",
    "    'rf__max_features': [None],\n",
    "    'rf__max_depth': [9],\n",
    "    'rf__min_samples_split': [2],\n",
    "    'rf__min_samples_leaf': [1]\n",
    "}\n",
    "\n",
    "# This model will be saved as rf_gs2:\n",
    "rf_gs = GridSearchCV(rf_pipe, \n",
    "                     cv=5, \n",
    "                     param_grid=parameters,\n",
    "                    )\n",
    "\n",
    "rf_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a6abd0c-57e6-49f7-a180-f412779839df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.19\n"
     ]
    }
   ],
   "source": [
    "#-------------------#\n",
    "# Model performance #\n",
    "#-------------------#\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred = rf_gs.predict(X_test)\n",
    "\n",
    "# Due to the imbalanced classes, just looking at F1 score here\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4ea736-39b6-41e2-9544-89d1067e16e0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7721ad9-27a8-4974-96dd-c0621a4431f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------#\n",
    "# Export the model #\n",
    "#------------------#\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Model to be pickled\n",
    "model = rf_gs\n",
    "\n",
    "# Pickling the model\n",
    "with open('QTOPICmodel.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
